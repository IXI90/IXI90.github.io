---
layout: post
comments: true
title:  "Quick Introduction to Reinforcement Learning: Part 2 - Dynamic Programming"
excerpt: "The different Bellman Equations will be introduced. Afterwards we discuss Value and Policy Iteration and sketch proofs of those dynamic programming algorithms. "
date:   2017-08-10
mathjax: true
---


### Dynamic Programming

Dynamic Programming (DP) is an optimization approach that transforms complex problems into overlapping, simpler sub-problems. In our context, the term DP refers to a class of algorithms that is able to compute optimal policies in a known MDP, i.e. $<\mathcal{S},\mathcal{A}, \mathcal{P}, \mathcal{R}, \gamma>$ is given. In later posts the assumption of a known environment will be dropped (model-free setting), but even in this case one will discover that the DP algorithms are still   